{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14040233,"sourceType":"datasetVersion","datasetId":8938971},{"sourceId":14162858,"sourceType":"datasetVersion","datasetId":9027310}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#We first need to install the older gradio version to meet compability with other modules\n!pip install gradio==5.35.0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gradio as gr\nimport torch\nimport timm\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom torchvision import transforms\nimport os\nimport shutil\n\n# Configurance\nCONFIG = {\n    \"img_size\": 224,\n    \"num_classes\": 3,\n    \"model_name\": \"swin_tiny_patch4_window7_224\",\n    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n}\nprint(\"Using device:\", CONFIG[\"device\"])\nprint(\"GPU available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"GPU name:\", torch.cuda.get_device_name(0))\n\nIDX2LABEL = {0: \"Healthy\", 1: \"Moderate\", 2: \"Severe\"}\n\ntest_tf = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n])\n\n# Load trained-Model\nmodel = timm.create_model(CONFIG['model_name'], pretrained=False, num_classes=CONFIG['num_classes'])\nmodel.load_state_dict(torch.load(\"/kaggle/input/test-best-model/best_sick_f1_model(1).pth\", map_location=CONFIG['device']))\nmodel.to(CONFIG['device'])\nmodel.eval()\n\n# Single Detecting Function\ndef predict_fn(img):\n    img = np.array(img)\n    img = cv2.resize(img, (CONFIG['img_size'], CONFIG['img_size']))\n    tensor = test_tf(img).unsqueeze(0).to(CONFIG['device'])\n    with torch.no_grad():\n        outputs = model(tensor)\n        probs = torch.softmax(outputs, dim=1)[0].cpu().numpy()\n        _, pred = torch.max(outputs, 1)\n\n    pred_label = IDX2LABEL[pred.item()]\n    prob_data = pd.DataFrame({\n        \"Class\": [IDX2LABEL[i] for i in range(CONFIG['num_classes'])],\n        \"Probability\": [float(probs[i]) for i in range(CONFIG['num_classes'])]\n    })\n\n    return pred_label, prob_data, prob_data\n\n# Batch-Detecting Function\ndef batch_predict_fn(file_obj):\n    results = []\n    if file_obj is None:\n        return pd.DataFrame(columns=[\"Image\", \"Prediction\", \"Healthy\", \"Moderate\", \"Severe\"])\n\n    if file_obj.name.endswith(\".zip\"):\n        import zipfile, tempfile\n        tmpdir = tempfile.mkdtemp()\n        with zipfile.ZipFile(file_obj.name, \"r\") as zip_ref:\n            zip_ref.extractall(tmpdir)\n        img_paths = [os.path.join(tmpdir, f) for f in os.listdir(tmpdir)]\n    else:\n        img_paths = [file_obj.name]\n\n    for path in img_paths:\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img_resized = cv2.resize(img, (CONFIG['img_size'], CONFIG['img_size']))\n        tensor = test_tf(img_resized).unsqueeze(0).to(CONFIG['device'])\n        with torch.no_grad():\n            outputs = model(tensor)\n            probs = torch.softmax(outputs, dim=1)[0].cpu().numpy()\n            _, pred = torch.max(outputs, 1)\n        pred_label = IDX2LABEL[pred.item()]\n        results.append([os.path.basename(path), pred_label, probs[0], probs[1], probs[2]])\n\n    df = pd.DataFrame(results, columns=[\"Image\", \"Prediction\", \"Healthy\", \"Moderate\", \"Severe\"])\n    return df\n\nwith gr.Blocks(theme=\"soft\") as demo:\n    gr.Markdown(\"\"\"\n    # ü©∫ Diabetic Retinopathy Severity Classification\n    ---\n    This demo uses a **Swin Transformer** model to classify retinal fundus images into three severity levels of diabetic retinopathy.  \n    - **Classes**: Healthy / Moderate / Severe  \n    - **Dataset**: APTOS 2019 (Kaggle)  \n    - **Model**: Swin-Tiny Patch4 Window7 224  \n\n    üåü *Early detection of diabetic retinopathy is crucial for preventing vision loss.*  \n    \"\"\")\n    \n    #Provide Example for Single Detecting\n    with gr.Tab(\"üîç Single Prediction\"):\n        with gr.Row():\n            with gr.Column(scale=1):\n                img_input = gr.Image(type=\"pil\", label=\"üì§ Upload Retinal Image\")\n                submit_btn = gr.Button(\"Run Prediction\")\n            with gr.Column(scale=1):\n                prediction = gr.Label(label=\"Final Prediction\")\n                prob_plot = gr.BarPlot(x=\"Class\", y=\"Probability\", label=\"Prediction Confidence\")\n                prob_table = gr.Dataframe(headers=[\"Class\",\"Probability\"], label=\"Numerical Probabilities\")\n\n        submit_btn.click(fn=predict_fn, inputs=img_input, outputs=[prediction, prob_plot, prob_table])\n\n        #\n        gr.Markdown(\"### üéØ Try with Example Images\")\n        gr.Examples(\n            examples=[\n                \"/kaggle/input/demonstration/class 2.png\",\n                \"/kaggle/input/demonstration/class 4.png\"\n            ],\n            inputs=img_input,\n            outputs=[prediction, prob_plot, prob_table],\n            fn=predict_fn,\n            label=\"Click an example image to run prediction\"\n        )\n\n    with gr.Tab(\"üìÇ Batch Prediction\"):\n        batch_input = gr.File(file_types=[\".zip\", \".jpg\", \".png\"], label=\"Upload multiple images or zip\")\n        batch_btn = gr.Button(\"Run Batch Prediction\")\n        batch_output = gr.Dataframe(headers=[\"Image\", \"Prediction\", \"Healthy\", \"Moderate\", \"Severe\"])\n        batch_btn.click(fn=batch_predict_fn, inputs=batch_input, outputs=batch_output)\n\n        # Provide Example for Batching-Detecting\n        gr.Markdown(\"### üì¶ Try with Example Batch\")\n        shutil.make_archive(\"/kaggle/working/batch_test\", 'zip', \"/kaggle/input/demonstration/test_batch\")\n        gr.Examples(\n            examples=[\n                \"/kaggle/working/batch_test.zip\"\n            ],\n            inputs=batch_input,\n            outputs=batch_output,\n            fn=batch_predict_fn,\n            label=\"Click to run batch example\"\n)\n    with gr.Tab(\"‚ÑπÔ∏è Model Info\"):\n        gr.Markdown(\"\"\"\n        ## üìñ Model Information\n        - **Architecture**: Swin Transformer Tiny  \n        - **Training Data**: APTOS 2019 (Kaggle)  \n        - **Performance**: Average Sick F1-score = 0.8277  \n        - **Metrics**: Precision, Recall, F1-score available  \n        \"\"\")\n\ndemo.launch(share=True, allowed_paths=[\"/kaggle/input/demonstration\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}